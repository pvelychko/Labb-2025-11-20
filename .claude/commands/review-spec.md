---
description: Review specifications, plans, or requirement documents for completeness, clarity, edge cases, and technical accuracy.
argument-hint: [Path to spec/plan document(s) or additional review focus areas]
---

# Review Specification or Plan Document
Thoroughly review specifications, implementation plans, PRDs, technical designs, or requirement documents to ensure they are complete, clear, unambiguous, and ready for implementation.


## Variables

SPEC_PATH_OR_FOCUS: $ARGUMENTS
*(Optional: Path to specific spec document(s) to review, or additional focus areas)*


## Instructions
- **Follow project guidelines** (CLAUDE.md, AGENTS.md, README.md)
- **Follow critical rules and guardrails** (`docs/checklists/CRITICAL-RULES-AND-GUARDRAILS.md`)
- **Follow relevant development guidelines**:
   - For Development tasks: `docs/guidelines/DEVELOPMENT-ARCHITECTURE-GUIDELINES.md`
   - For UI/UX tasks: `docs/guidelines/UX-UI-GUIDELINES.md`
   - See also other guidelines in `docs/guidelines/` as needed
- **Read-only review** - No modifications to specs during analysis
- **Be thorough and critical** - Challenge assumptions, find edge cases, identify ambiguities
- **Favor simplicity** - Actively identify over-engineering; recommend simplest solution (KISS, YAGNI, DRY)
- **Be concise** - Avoid unnecessary prose, minimize code listings (use pseudo code when possible)


## Workflow

### Phase 1: Discovery and Context

1. **Locate specification documents**
   - If _`SPEC_PATH_OR_FOCUS`_ is provided, review those documents/areas
   - If not, search common locations: `docs/specs/`, `docs/design/`, `docs/architecture/`, `docs/planning/`, `docs/requirements/`   
   - List all documents found and their relationships

2. **Build context**
   - Understand existing patterns, conventions, tech stack
   - Identify problem being solved, success criteria, scope boundaries
   - Note dependencies, constraints, and assumptions

**Gate**: All relevant specs identified and context understood


### Phase 2: Completeness Review

Verify specification covers all necessary aspects:

1. **Functional requirements** - Features, workflows, use cases, success/error states
2. **Non-functional requirements** - Performance, security, accessibility, i18n, compatibility
3. **Technical specifications** - Data models, APIs, integrations, error handling, monitoring
4. **Edge cases and errors** - Validation rules, timeouts, retries, error messages, boundary conditions
5. **Testing strategy** - Acceptance criteria, test approach, test scenarios
6. **Operations** - Deployment, configuration, monitoring, rollback, maintenance

Document all missing or incomplete areas.

**Gate**: Completeness assessment finished


### Phase 3: Clarity and Ambiguity Review

Identify unclear, ambiguous, or contradictory specifications:

1. **Language precision** - Check for vague terms ("fast", "user-friendly"), conflicting requirements, undefined terms
2. **Implementation clarity** - Verify developers can implement without guessing, acceptance criteria are testable
3. **Missing details** - Find TBD/TODO items, referenced missing documents, unvalidated assumptions
4. **Consistency** - Verify consistency across sections, examples match specs, naming is consistent

Document all ambiguities and clarity issues.

**Gate**: All ambiguities identified


### Phase 4: Technical Accuracy and Standards

Verify technical solutions use current best practices:

1. **Technology versions** - Check if libraries/frameworks use latest stable versions, identify deprecated APIs
2. **Best practices** - Verify industry standards, security (OWASP), accessibility (WCAG 2.1+), project patterns
3. **Technical feasibility** - Assess if solution is feasible, identify risks, verify performance expectations
4. **Documentation lookup** - Use @agent-documentation-lookup to verify latest APIs, best practices, deprecations


**Gate**: Technical accuracy verified


### Phase 5: Edge Cases and Risk Analysis

Identify missing edge cases and risks:

1. **Edge cases inventory**
   - Empty/maximum states, invalid input, concurrent access
   - Network failures, third-party failures, data migration
   - Browser/platform-specific issues

2. **User journey edge cases** - Unexpected action order, navigation away mid-process, multiple tabs/sessions

3. **Security edge cases** - Malicious input, privilege escalation, injection attacks, data leakage

4. **Risk assessment** - Identify highest risks, potential failures, invalid assumptions, dependency risks

**Gate**: Comprehensive edge case analysis complete


### Phase 6: Scope and Architecture Validation

Ensure scope is well-defined and architecture is sound:

1. **Scope validation**
   - Verify in-scope items are necessary and achievable
   - Confirm out-of-scope items are explicitly stated
   - Identify scope creep risks, phase boundaries
   - Challenge "nice-to-haves" masquerading as requirements

2. **Architecture review**
   - Assess architectural soundness, component separation, separation of concerns
   - Evaluate scalability, performance, maintainability
   - Review integration points, API contracts, data flows

3. **Over-engineering detection** (CRITICAL)
   - **Unnecessary complexity**: Custom implementations when standard libraries/patterns exist, premature abstractions, overly generic solutions
   - **Premature optimization**: Performance optimizations without measured need, caching/pooling without proven bottlenecks
   - **Excessive layering**: Unnecessary indirection, wrapper classes without clear benefit, over-abstracted interfaces
   - **Feature bloat**: Speculative features for "future flexibility", unused configuration options, gold-plating
   - **Technology overkill**: Complex tools/frameworks when simpler ones suffice, microservices where monolith works, unnecessary dependencies
   - **Pattern misapplication**: Design patterns used without clear need, architecture patterns inappropriate for scale

   For each identified issue, recommend **simplest solution** that meets actual requirements.

**Use @agent-solution-architect** for deep architectural review if spec contains significant architectural decisions.

**Gate**: Scope and architecture validated, over-engineering identified


### Phase 7: Stakeholder and Success Criteria

Validate stakeholder needs and measurable success criteria:

1. **Stakeholder alignment** - Verify all needs addressed, no conflicting requirements, user perspective represented
2. **Success criteria** - Confirm criteria are specific, measurable, objective, and testable
3. **User experience** - Check UX specification, user journeys, error states, user-centered design

**Gate**: Stakeholder needs and success criteria validated


### Phase 8: Review Report Generation

Generate comprehensive review report with prioritized findings:

1. **Categorize findings** - Critical (must fix before implementation), High (should fix), Medium (can fix during), Low (nice-to-have)
2. **Specific recommendations** - For each issue, provide concrete suggestion with examples and rationale
3. **Risk highlights** - Call out biggest risks and areas likely to cause implementation issues
4. **Readiness assessment** - Overall assessment: Ready / Needs Minor Updates / Needs Significant Rework / Not Ready

**Gate**: Comprehensive review report generated


## Report

Your job is *ONLY* to review and generate report. Do *NOT* modify specification documents.

Generate markdown report with:
- **Executive Summary** - What was reviewed, overall assessment, high-level findings, key recommendations
- **Scope and Context** - What spec achieves, scope boundaries, assumptions, context issues
- **Completeness Analysis** - Missing requirements by category, completeness assessment
- **Clarity Issues** - Ambiguous/vague requirements with suggested improvements
- **Technical Accuracy** - Version issues, deprecated approaches, standards compliance, feasibility concerns
- **Edge Cases and Risks** - Missing edge cases by category, security concerns, risk mitigation
- **Architecture Assessment** - Soundness, scalability, maintainability, integration clarity
- **Over-Engineering Analysis** - Unnecessary complexity, premature optimizations, excessive layering, feature bloat, technology overkill, pattern misapplication (with simpler alternatives)
- **Stakeholder Alignment** - Success criteria clarity, stakeholder needs, UX considerations
- **Prioritized Recommendations** - Critical/High/Medium/Low issues with specific suggestions
- **Readiness Assessment** - Can implementation start? What must be fixed? Next steps

Store report in: `<project_root>/docs/temp/spec-reviews/<spec-name>-review-<YYYY-MM-DD>.md`

Inform user of report location when complete.


## Post-Review

After report, ask user if they'd like to:
1. Update specification based on findings
2. Focus on specific areas for deeper review
3. Proceed to implementation (if ready)
4. Escalate critical issues for clarification
